{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Nearest Neighbor Classifiers\n",
    "\n",
    "**Nearest Neighbors**, can be used to determine the class label of the test instance. The justification for using nearest neighbors is best exemplified by the following saying: *“If it walks like a duck, quacks like a duck, and looks like a duck, then it’s probably a duck.”*\n",
    "\n",
    "A nearest neighbor classifier represents each example as a data point in a **d-dimensional** space, where $d$ is the number of attribute. \n",
    "\n",
    "Given a test instance, we compute its proximity to the training instances according to one of the proximity measures. \n",
    "The k-nearest neighbors of a given test instance $z$ refer to the k training examples that are closest to $z$.\n",
    "<space>\n",
    "![knn-1](knn-1.png)\n",
    "![knn-1](knn-2.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdb86bd154f3e470"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 1) Algorithm\n",
    "\n",
    " The algorithm computes the distance (or similarity) between each test instance $z = (x′,y′)$ and all the training examples $(x,y) ∈ D$ to determine its nearest neighbor list, $Dz$.\n",
    " \n",
    "Such computation can be costly if the number of training examples is large. However, efficient indexing techniques are available to reduce the computation needed to find the nearest neighbors of a test instance.\n",
    "<space>\n",
    "![knn-1](knn-Algo.png)\n",
    "<space>\n",
    "Once the nearest neighbor list is obtained, the test instance is classified based on the majority class of its nearest neighbors:\n",
    "\n",
    "$$\n",
    "Majority \\hspace{0.5cm} Voting : y' = \\underset{v}{argmax} \\sum_{(x_i, y_i)\\in D_z} I(v=y_i)\n",
    "$$\n",
    "\n",
    "where $v$ is a class label, $yi$ is the class label for one of the nearest neighbors, and $I(·)$ is an indicator function that returns the value 1 if its argument is true and 0 otherwise.\n",
    "\n",
    "In the majority voting approach, every neighbor has the same impact on the classification. This makes the algorithm sensitive to the choice of $k$, as shown in figure. One way to reduce the impact of $k$ is to weight the influence of each nearest neighbor $xi$ according to its distance: \n",
    "\n",
    "$$wi = \\frac{1}{d(x′,xi)^2} $$ \n",
    "\n",
    "As a result, training examples that are located far away from *z* have a weaker impact on the classification compared to those that are located close to *z*. Using the distance-weighted voting scheme, the class label can be determined as follows:\n",
    "\n",
    "$$\n",
    "Distance-Weighted \\hspace{0.5cm} Voting : y' = \\underset{v}{argmax} \\sum_{(x_i, y_i)\\in D_z} w_i * I(v=y_i)\n",
    "$$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a79321ab717100f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Functions\n",
    "\n",
    "The choice of the best distance function for k-Nearest Neighbors (kNN) depends on the nature of your data and the specific characteristics of your problem. Different distance functions may perform better in different scenarios. Here are some commonly used distance functions in kNN and their typical use cases:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a664c7d25f8f8702"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1) Euclidean Distance\n",
    "In the k-Nearest Neighbors (k-NN) algorithm, Euclidean Distance is a commonly used metric to measure the distance between data points.\n",
    "In the context of the k-NN algorithm, the Euclidean Distance is often used to find the k-nearest neighbors of a given data point. The algorithm calculates the distances between the query point and all other points in the dataset, and then selects the k points with the shortest Euclidean distances as its neighbors. \n",
    "\n",
    "$$\n",
    "Euclidean \\hspace{0.2cm} Distance = \\sqrt{\\sum^n_{i=1} (x_{2i} - x_{1i} )^2}\n",
    "$$\n",
    "\n",
    "\n",
    "This is the first function that we have observed, and it does not increase the accuracy. The characteristics of this function include:\n",
    "\n",
    "- Being the most common and widely used.\n",
    "- Suitability for continuous numerical data.\n",
    "- Sensitivity to magnitudes and scales of variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b793115e305c1e6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2) Manhattan Distance (L1 Norm)\n",
    "\n",
    "In the context of the k-nearest neighbors (KNN) algorithm, Manhattan Distance, also known as L1 Norm or Taxicab Distance, is a measure of the distance between two points in a grid-based system (like a city grid).\n",
    "\n",
    "$$\n",
    "Manhattan \\hspace{0.2cm} Distance = \\sum^n_{i=1} |a_i - b_i|\n",
    "$$\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Suitable for data with a grid-like structure (e.g., images).\n",
    "- Less sensitive to outliers compared to Euclidean distance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c404deba19261fa2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3) Minkowski Distance\n",
    "\n",
    "The Minkowski Distance is a generalization of both the Euclidean Distance (L2 Norm) and the Manhattan Distance (L1 Norm). It is a distance metric that includes both of these distance measures as special cases. The Minkowski Distance can be expressed in general terms for a multidimensional space as:\n",
    "$$\n",
    "Minkowski \\hspace{0.2cm} Distance = (\\sum^n_{i=1} |a_i - b_i|^p)^{1/p}\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Generalization of both Euclidean and Manhattan distances.\n",
    "- Parameterized by the \"p\" value, where p=2 is equivalent to Euclidean, and p=1 is equivalent to Manhattan."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c166b54f90cd49"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4) Cosine Similarity\n",
    "Cosine Similarity is a measure of similarity between two non-zero vectors of an inner product space. In the context of the K-nearest neighbors (KNN) algorithm, it is often used as a distance metric to measure the similarity between two data points.\n",
    "\n",
    "This distance metric is often used when dealing with high-dimensional data, such as text data or data represented as vectors in a high-dimensional space. Cosine Similarity is particularly useful in scenarios where the magnitude of the vectors is not as important as the direction, making it effective for comparing documents, text, or feature vectors.\n",
    "\n",
    "$$\n",
    "Cosine \\hspace{0.2cm} Similarity = \\frac{A*B}{||A||*||B||}\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Suitable for high-dimensional data like text data, document similarity, and recommendation systems.\n",
    "- Ignores the magnitude of vectors and focuses on the direction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3763528eaf6fbe4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5) Hamming Distance\n",
    "\n",
    "Hamming Distance is a metric used to measure the difference between two strings of equal length. It counts the number of positions at which the corresponding symbols (characters or bits) are different.\n",
    "\n",
    "In the context of the K-nearest neighbors (KNN) algorithm, Hamming Distance can be used as a distance metric when dealing with categorical data or binary feature vectors. \n",
    "\n",
    "$$\n",
    "Hamming \\hspace{0.2cm} Distance = Number \\hspace{0.2cm} of  \\hspace{0.2cm} positions \\hspace{0.2cm} with \\hspace{0.2cm} different \\hspace{0.2cm} symbols\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Specifically used for categorical data and binary features.\n",
    "- Measures the number of positions at which corresponding bits are different.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94268cd24f2a8d0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.6) Chebyshev Distance\n",
    "\n",
    "Chebyshev Distance, also known as $L_∞$ Norm or maximum metric, is a distance metric that measures the maximum absolute difference between the coordinates of corresponding elements in two vectors.\n",
    "\n",
    "In the context of the K-nearest neighbors (KNN) algorithm, Chebyshev Distance can be used as a distance metric to measure dissimilarity between data points.\n",
    " \n",
    "$$\n",
    "Chebyshev \\hspace{0.2cm} Distance = max(|a_1 - b_1|, |a_2-b_2|,... ,|n_1-n_2| )\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Measures the maximum absolute difference between corresponding components.\n",
    "- Suitable for scenarios where you are interested in the most significant difference between dimensions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c990bbd8cad4aec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.7) Mahalanobis Distance\n",
    "Mahalanobis Distance is a measure of the distance between a point and a distribution, taking into account the correlation between variables.\n",
    "\n",
    "In the context of the K-nearest neighbors (KNN) algorithm, Mahalanobis Distance can be used as a distance metric to identify the nearest neighbors of a data point. \n",
    "$$\n",
    "Mahalanobis \\hspace{0.2cm} Distance = \\sqrt{X-\\mu)^T \\sum^{-1}(X-\\mu)}\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Measures the maximum absolute difference between corresponding components.\n",
    "- Suitable for scenarios where you are interested in the most significant difference between dimensions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fd2e6a82032c444"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.8) Jaccard Distance\n",
    "Jaccard Distance is a measure of dissimilarity between two sets. \n",
    "\n",
    "In the context of the K-nearest neighbors (KNN) algorithm, Jaccard Distance can be used as a dissimilarity metric for sets of features or binary vectors. \n",
    "$$\n",
    "Jaccard \\hspace{0.2cm} Distance = 1- \\frac{|A \\cap B|}{|A \\cup B|}\n",
    "$$\n",
    "\n",
    "The characteristics of this function include:\n",
    "\n",
    "- Used for comparing set data, often in the context of text analysis.\n",
    "- Measures the dissimilarity between two sets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3299d9fb18ce7508"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.9) Custom Distance Function\n",
    "You may need a custom distance function based on domain knowledge or specific requirements."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c10381c78b0c86cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Dataset Example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "586e7560d31aeff9"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:00.966188Z",
     "start_time": "2024-01-27T16:11:00.849976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "       SquareFeet  Bedrooms  Bathrooms Neighborhood  YearBuilt          Price\n0            2126         4          1        Rural       1969  215355.283618\n1            2459         3          2        Rural       1980  195014.221626\n2            1860         2          1       Suburb       1970  306891.012076\n3            2294         2          1        Urban       1996  206786.787153\n4            2130         5          2       Suburb       2001  272436.239065\n...           ...       ...        ...          ...        ...            ...\n49995        1282         5          3        Rural       1975  100080.865895\n49996        2854         2          2       Suburb       1988  374507.656727\n49997        2979         5          3       Suburb       1962  384110.555590\n49998        2596         5          2        Rural       1984  380512.685957\n49999        1572         5          3        Rural       2011  221618.583218\n\n[50000 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SquareFeet</th>\n      <th>Bedrooms</th>\n      <th>Bathrooms</th>\n      <th>Neighborhood</th>\n      <th>YearBuilt</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2126</td>\n      <td>4</td>\n      <td>1</td>\n      <td>Rural</td>\n      <td>1969</td>\n      <td>215355.283618</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2459</td>\n      <td>3</td>\n      <td>2</td>\n      <td>Rural</td>\n      <td>1980</td>\n      <td>195014.221626</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1860</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Suburb</td>\n      <td>1970</td>\n      <td>306891.012076</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2294</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Urban</td>\n      <td>1996</td>\n      <td>206786.787153</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2130</td>\n      <td>5</td>\n      <td>2</td>\n      <td>Suburb</td>\n      <td>2001</td>\n      <td>272436.239065</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>1282</td>\n      <td>5</td>\n      <td>3</td>\n      <td>Rural</td>\n      <td>1975</td>\n      <td>100080.865895</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>2854</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Suburb</td>\n      <td>1988</td>\n      <td>374507.656727</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>2979</td>\n      <td>5</td>\n      <td>3</td>\n      <td>Suburb</td>\n      <td>1962</td>\n      <td>384110.555590</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>2596</td>\n      <td>5</td>\n      <td>2</td>\n      <td>Rural</td>\n      <td>1984</td>\n      <td>380512.685957</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>1572</td>\n      <td>5</td>\n      <td>3</td>\n      <td>Rural</td>\n      <td>2011</td>\n      <td>221618.583218</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"housing_price_dataset.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "              count           mean           std           min            25%  \\\nSquareFeet  50000.0    2006.374680    575.513241   1000.000000    1513.000000   \nBedrooms    50000.0       3.498700      1.116326      2.000000       3.000000   \nBathrooms   50000.0       1.995420      0.815851      1.000000       1.000000   \nYearBuilt   50000.0    1985.404420     20.719377   1950.000000    1967.000000   \nPrice       50000.0  224827.325151  76141.842966 -36588.165397  169955.860225   \n\n                      50%            75%            max  \nSquareFeet    2007.000000    2506.000000    2999.000000  \nBedrooms         3.000000       4.000000       5.000000  \nBathrooms        2.000000       3.000000       3.000000  \nYearBuilt     1985.000000    2003.000000    2021.000000  \nPrice       225052.141166  279373.630052  492195.259972  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SquareFeet</th>\n      <td>50000.0</td>\n      <td>2006.374680</td>\n      <td>575.513241</td>\n      <td>1000.000000</td>\n      <td>1513.000000</td>\n      <td>2007.000000</td>\n      <td>2506.000000</td>\n      <td>2999.000000</td>\n    </tr>\n    <tr>\n      <th>Bedrooms</th>\n      <td>50000.0</td>\n      <td>3.498700</td>\n      <td>1.116326</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>Bathrooms</th>\n      <td>50000.0</td>\n      <td>1.995420</td>\n      <td>0.815851</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>YearBuilt</th>\n      <td>50000.0</td>\n      <td>1985.404420</td>\n      <td>20.719377</td>\n      <td>1950.000000</td>\n      <td>1967.000000</td>\n      <td>1985.000000</td>\n      <td>2003.000000</td>\n      <td>2021.000000</td>\n    </tr>\n    <tr>\n      <th>Price</th>\n      <td>50000.0</td>\n      <td>224827.325151</td>\n      <td>76141.842966</td>\n      <td>-36588.165397</td>\n      <td>169955.860225</td>\n      <td>225052.141166</td>\n      <td>279373.630052</td>\n      <td>492195.259972</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:00.978283Z",
     "start_time": "2024-01-27T16:11:00.899498Z"
    }
   },
   "id": "4c667f5a14957e37"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   SquareFeet    50000 non-null  int64  \n",
      " 1   Bedrooms      50000 non-null  int64  \n",
      " 2   Bathrooms     50000 non-null  int64  \n",
      " 3   Neighborhood  50000 non-null  object \n",
      " 4   YearBuilt     50000 non-null  int64  \n",
      " 5   Price         50000 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:00.979640Z",
     "start_time": "2024-01-27T16:11:00.918984Z"
    }
   },
   "id": "b35e511f12f5dfcb"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1000 1001 1002 ... 2997 2998 2999]\n",
      "1 [2 3 4 5]\n",
      "2 [1 2 3]\n",
      "3 ['Rural' 'Suburb' 'Urban']\n",
      "4 [1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963\n",
      " 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977\n",
      " 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991\n",
      " 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005\n",
      " 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019\n",
      " 2020 2021]\n",
      "5 [-36588.16539749 -28774.99802221 -24715.24248213 ... 476671.73326267\n",
      " 482577.16340543 492195.25997202]\n"
     ]
    }
   ],
   "source": [
    "num_inst, num_features = data.shape\n",
    "# elem = [ np.unique(data_proc.iloc[:,f]) for f in range(num_features)]\n",
    "for f in range(num_features):\n",
    "    print (f, np.unique(data.iloc[:,f])) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:00.980262Z",
     "start_time": "2024-01-27T16:11:00.938085Z"
    }
   },
   "id": "922948f748648c92"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "Neighborhood\nSuburb    16721\nRural     16676\nUrban     16603\nName: count, dtype: int64"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Neighborhood\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:00.985440Z",
     "start_time": "2024-01-27T16:11:00.969523Z"
    }
   },
   "id": "696be5b48985f5ee"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# drop label columns\n",
    "X = data.drop(columns=[\"Neighborhood\"])\n",
    "\n",
    "# isolate y\n",
    "y = data[\"Neighborhood\"]\n",
    "\n",
    "# split in Train-set(80%) and Testing-set(20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.098928Z",
     "start_time": "2024-01-27T16:11:01.002437Z"
    }
   },
   "id": "da85178f1c79e5f1"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 33500 entries, 23990 to 15795\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SquareFeet  33500 non-null  int64  \n",
      " 1   Bedrooms    33500 non-null  int64  \n",
      " 2   Bathrooms   33500 non-null  int64  \n",
      " 3   YearBuilt   33500 non-null  int64  \n",
      " 4   Price       33500 non-null  float64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 1.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 16500 entries, 33553 to 28203\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SquareFeet  16500 non-null  int64  \n",
      " 1   Bedrooms    16500 non-null  int64  \n",
      " 2   Bathrooms   16500 non-null  int64  \n",
      " 3   YearBuilt   16500 non-null  int64  \n",
      " 4   Price       16500 non-null  float64\n",
      "dtypes: float64(1), int64(4)\n",
      "memory usage: 773.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.info(), X_test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.115047Z",
     "start_time": "2024-01-27T16:11:01.013188Z"
    }
   },
   "id": "8f6c5890f361dd1e"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "       SquareFeet  Bedrooms  Bathrooms  YearBuilt          Price\n33553        1894         5          1       1975  170835.035713\n9427         1001         5          3       1963  126913.469998\n199          2264         4          3       1964  246611.883092\n12447        2299         5          1       1999  244250.462969\n39489        2651         2          1       1951  271127.650112\n...           ...       ...        ...        ...            ...\n27615        2647         2          3       1951  291504.040710\n21964        1300         3          3       1958  193917.029039\n33321        1181         5          1       2003  118758.460607\n40225        2513         2          1       1995  259968.166763\n28203        2899         2          3       1960  289685.873746\n\n[16500 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SquareFeet</th>\n      <th>Bedrooms</th>\n      <th>Bathrooms</th>\n      <th>YearBuilt</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33553</th>\n      <td>1894</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1975</td>\n      <td>170835.035713</td>\n    </tr>\n    <tr>\n      <th>9427</th>\n      <td>1001</td>\n      <td>5</td>\n      <td>3</td>\n      <td>1963</td>\n      <td>126913.469998</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>2264</td>\n      <td>4</td>\n      <td>3</td>\n      <td>1964</td>\n      <td>246611.883092</td>\n    </tr>\n    <tr>\n      <th>12447</th>\n      <td>2299</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1999</td>\n      <td>244250.462969</td>\n    </tr>\n    <tr>\n      <th>39489</th>\n      <td>2651</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1951</td>\n      <td>271127.650112</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27615</th>\n      <td>2647</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1951</td>\n      <td>291504.040710</td>\n    </tr>\n    <tr>\n      <th>21964</th>\n      <td>1300</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1958</td>\n      <td>193917.029039</td>\n    </tr>\n    <tr>\n      <th>33321</th>\n      <td>1181</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2003</td>\n      <td>118758.460607</td>\n    </tr>\n    <tr>\n      <th>40225</th>\n      <td>2513</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1995</td>\n      <td>259968.166763</td>\n    </tr>\n    <tr>\n      <th>28203</th>\n      <td>2899</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1960</td>\n      <td>289685.873746</td>\n    </tr>\n  </tbody>\n</table>\n<p>16500 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.115535Z",
     "start_time": "2024-01-27T16:11:01.022860Z"
    }
   },
   "id": "5ab0c68d9e7f6508"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def process_data_x(train, test):\n",
    "    numerical_idx = [\"SquareFeet\", \"Bedrooms\", \"Bathrooms\", \"YearBuilt\", \"Price\"]\n",
    "    \n",
    "    # convert numeric integer to float and concat them with already float feature \n",
    "    # There are no NaN element in these feature\n",
    "    for col in range(0,4):\n",
    "        X_train[numerical_idx[col]] = pd.to_numeric(train[numerical_idx[col]],downcast='float')\n",
    "    \n",
    "    # --------------\n",
    "    # process test\n",
    "    \n",
    "    # convert numeric integer to float and concat them with already float feature \n",
    "    # There are no NaN element in these feature\n",
    "    for col in range(0,4):\n",
    "        X_test[numerical_idx[col]] = pd.to_numeric(test[numerical_idx[col]],downcast='float')\n",
    "    \n",
    "    return X_train, X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.122299Z",
     "start_time": "2024-01-27T16:11:01.028962Z"
    }
   },
   "id": "222a37e56ba7f91"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "X_train_enc, X_test_enc = process_data_x(X_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.127963Z",
     "start_time": "2024-01-27T16:11:01.031176Z"
    }
   },
   "id": "fe801cab05dc6519"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "       SquareFeet  Bedrooms  Bathrooms  YearBuilt          Price\n33553      1894.0       5.0        1.0     1975.0  170835.035713\n9427       1001.0       5.0        3.0     1963.0  126913.469998\n199        2264.0       4.0        3.0     1964.0  246611.883092\n12447      2299.0       5.0        1.0     1999.0  244250.462969\n39489      2651.0       2.0        1.0     1951.0  271127.650112\n...           ...       ...        ...        ...            ...\n27615      2647.0       2.0        3.0     1951.0  291504.040710\n21964      1300.0       3.0        3.0     1958.0  193917.029039\n33321      1181.0       5.0        1.0     2003.0  118758.460607\n40225      2513.0       2.0        1.0     1995.0  259968.166763\n28203      2899.0       2.0        3.0     1960.0  289685.873746\n\n[16500 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SquareFeet</th>\n      <th>Bedrooms</th>\n      <th>Bathrooms</th>\n      <th>YearBuilt</th>\n      <th>Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33553</th>\n      <td>1894.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1975.0</td>\n      <td>170835.035713</td>\n    </tr>\n    <tr>\n      <th>9427</th>\n      <td>1001.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>1963.0</td>\n      <td>126913.469998</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>2264.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1964.0</td>\n      <td>246611.883092</td>\n    </tr>\n    <tr>\n      <th>12447</th>\n      <td>2299.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1999.0</td>\n      <td>244250.462969</td>\n    </tr>\n    <tr>\n      <th>39489</th>\n      <td>2651.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1951.0</td>\n      <td>271127.650112</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27615</th>\n      <td>2647.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1951.0</td>\n      <td>291504.040710</td>\n    </tr>\n    <tr>\n      <th>21964</th>\n      <td>1300.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>1958.0</td>\n      <td>193917.029039</td>\n    </tr>\n    <tr>\n      <th>33321</th>\n      <td>1181.0</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>2003.0</td>\n      <td>118758.460607</td>\n    </tr>\n    <tr>\n      <th>40225</th>\n      <td>2513.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1995.0</td>\n      <td>259968.166763</td>\n    </tr>\n    <tr>\n      <th>28203</th>\n      <td>2899.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1960.0</td>\n      <td>289685.873746</td>\n    </tr>\n  </tbody>\n</table>\n<p>16500 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.133304Z",
     "start_time": "2024-01-27T16:11:01.043857Z"
    }
   },
   "id": "5a89588936a47ddf"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()\n",
    "\n",
    "y_train_enc = label_enc.fit_transform(y_train)\n",
    "y_test_enc = label_enc.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.181640Z",
     "start_time": "2024-01-27T16:11:01.055555Z"
    }
   },
   "id": "91c1dee58ad60de8"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "StandardScaler()",
      "text/html": "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_enc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.182200Z",
     "start_time": "2024-01-27T16:11:01.065643Z"
    }
   },
   "id": "21c7574edc3a11ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4) K Parameter\n",
    "\n",
    "In the L-Nearest Neighbors (K-NN) algorithm, the k parameter is one of the most important factors for the quality of the model. Choosing the best k is not so easy because it depends on the specific characteristics of the problem and the types of data we have, for example:\n",
    "\n",
    "- If **k is too small**, it is sensitive to noise points\n",
    "- If **K too large**, like k=+∞, it can be computationally expensive\n",
    "    $$\n",
    "        w = \\frac{1}{d^2}\n",
    "    $$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6860f1bb7b08b89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1) K too small\n",
    "\n",
    " The parameter \"k\" represents the number of neighbors to consider. Choosing an appropriate value for k is crucial, and setting it too small can lead to various issues.\n",
    "\n",
    "If you set k too small in kNN:\n",
    "\n",
    "1. **Overfitting:** With a small value of k, the model may become too sensitive to noise and outliers in the data. It might end up capturing the local variations in the training data, leading to poor generalization on new, unseen data.\n",
    "\n",
    "<space>\n",
    "\n",
    "2. **High Variance:** Small values of k can result in a higher variance, causing the model to be overly influenced by the specific data points in the training set. This can make the model less robust and more prone to changes in the training data.\n",
    "\n",
    "<space>\n",
    "\n",
    "3. **Increased Sensitivity to Outliers:** A small k may make the algorithm more sensitive to outliers because it considers fewer neighbors when making predictions. Outliers can have a significant impact on the decision boundaries, leading to misclassifications.\n",
    "\n",
    "<space>\n",
    "\n",
    "4. **Loss of Global Patterns:** A small k might focus too much on local patterns and fail to capture the broader trends or structures in the data. This can lead to poor generalization on new, unseen instances."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f76ea682a2f3b945"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.330\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "kNN.fit(scaler.transform(X_train_enc),y_train_enc)\n",
    "\n",
    "y_pred = kNN.predict(scaler.transform(X_test_enc))\n",
    "\n",
    "acc = accuracy_score(y_true=y_test_enc, y_pred=y_pred)\n",
    "print (f\"Accuracy {acc:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:01.372537Z",
     "start_time": "2024-01-27T16:11:01.075507Z"
    }
   },
   "id": "93483a9ef115da81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2) K too Large\n",
    "\n",
    "\n",
    "If you set the value of k in k-Nearest Neighbors (kNN) too large, it can lead to different challenges and drawbacks:\n",
    "\n",
    "1. **Smoothing Effect:** A larger k means considering a greater number of neighbors, potentially resulting in a more generalized and smoothed decision boundary. This can lead to the model overlooking local patterns and variations in the data, making it less sensitive to the underlying structure.\n",
    "\n",
    "<space>\n",
    "\n",
    "2. **Loss of Sensitivity to Local Patterns:** With a large k, the model may become less sensitive to variations in the local neighborhood of a data point. This can be problematic when dealing with datasets that have intricate local patterns or when different regions of the feature space exhibit distinct characteristics.\n",
    "\n",
    "<space>\n",
    "\n",
    "3. **Increased Computational Complexity:** As k increases, the computational complexity of the algorithm also grows. Calculating distances and finding the k-nearest neighbors becomes more resource-intensive. This can be a concern, especially when dealing with large datasets.\n",
    "\n",
    "<space>\n",
    "\n",
    "4. **Impact of Irrelevant Features:** A larger k might give more weight to irrelevant features, leading to poor performance. In cases where certain features are not informative for the task at hand, including them in the kNN calculation with a large k can introduce noise and degrade the model's accuracy.\n",
    "\n",
    "<space>\n",
    "\n",
    "5. **Risk of Misclassification in Imbalanced Datasets:** In imbalanced datasets where one class significantly outnumbers the others, a large k may result in predictions being biased towards the majority class. This is because a large k could include more neighbors from the majority class, potentially overshadowing the minority class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ba542e7be4546fd"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.332\n"
     ]
    }
   ],
   "source": [
    "kNN = KNeighborsClassifier(n_neighbors=3000)\n",
    "\n",
    "kNN.fit(scaler.transform(X_train_enc),y_train_enc)\n",
    "\n",
    "y_pred = kNN.predict(scaler.transform(X_test_enc))\n",
    "\n",
    "acc = accuracy_score(y_true=y_test_enc, y_pred=y_pred)\n",
    "print (f\"Accuracy {acc:.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:12.987838Z",
     "start_time": "2024-01-27T16:11:01.354708Z"
    }
   },
   "id": "36ec89f43e75e15d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3) K correct size\n",
    "\n",
    "The choice of the correct value for \\( k \\) in k-Nearest Neighbors (kNN) depends on the specific characteristics of your dataset and the nature of the problem you're trying to solve. There is no one-size-fits-all answer, and it often involves experimentation and validation.\n",
    "\n",
    "Here are some general guidelines:\n",
    "\n",
    "1. **Odd Values for Binary Classification:** If you're dealing with a binary classification problem, it's often recommended to use an odd value for \\( k \\) to avoid ties when determining the majority class. This helps prevent situations where an equal number of neighbors from each class might lead to ambiguous predictions.\n",
    "\n",
    "<space>\n",
    "\n",
    "2. **Consider the Size of the Dataset:** If your dataset is small, using a smaller \\( k \\) value might be more appropriate. However, in larger datasets, a slightly larger \\( k \\) might be beneficial.\n",
    "\n",
    "<space>\n",
    "\n",
    "3. **Cross-Validation:** Use cross-validation techniques to assess the performance of your kNN model with different \\( k \\) values. This helps you choose a value that generalizes well to unseen data.\n",
    "\n",
    "<space>\n",
    "\n",
    "4. **Explore a Range of \\( k \\) Values:** Instead of settling on a single \\( k \\) value, consider evaluating the model's performance with a range of \\( k \\) values. This can give you insights into how sensitive your model is to the choice of \\( k \\) and help you find an optimal value.\n",
    "\n",
    "<space>\n",
    "\n",
    "5. **Domain Knowledge:** Consider any domain-specific knowledge or insights you may have about the problem. For example, if you know that certain patterns in the data occur at a specific scale, it might guide your choice of \\( k \\)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40f91722e7dd4943"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1 | Accuracy 0.334\n",
      "k:  2 | Accuracy 0.334\n",
      "k:  3 | Accuracy 0.339\n",
      "k:  4 | Accuracy 0.337\n",
      "k:  5 | Accuracy 0.335\n",
      "k:  6 | Accuracy 0.339\n",
      "k:  7 | Accuracy 0.340\n",
      "k:  8 | Accuracy 0.337\n",
      "k:  9 | Accuracy 0.338\n",
      "k: 10 | Accuracy 0.339\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,11):\n",
    "    kNN = KNeighborsClassifier(n_neighbors=k)\n",
    "    kNN.fit(X_train_enc,y_train_enc)\n",
    "    y_pred = kNN.predict(X_test_enc)\n",
    "\n",
    "    # compute Accuracy\n",
    "    acc = accuracy_score(y_true=y_test_enc, y_pred=y_pred)\n",
    "    print (f\"k: {k:2d} | Accuracy {acc:.3f}\" )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:15.435244Z",
     "start_time": "2024-01-27T16:11:12.990730Z"
    }
   },
   "id": "3e664fefc5e1e211"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5) Advantages And Disadvantages of KNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b729762093a130f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.1 ) Advantages \n",
    "\n",
    "1. **No Training Period**- KNN modeling does not include training period as the data itself is a model which will be the reference for future prediction and because of this it is very time efficient in term of improvising for a random modeling on the available data.\n",
    "<space>\n",
    "\n",
    "2. **Easy Implementation**- KNN is very easy to implement as the only thing to be calculated is the distance between different points on the basis of data of different features and this distance can easily be calculated using distance formula such as- Euclidian or Manhattan\n",
    "<space>\n",
    "\n",
    "3. As there is no training period thus new data can be added at any time since it wont affect the model.\n",
    "\n",
    "You can see this part above "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c5457d44ba39a6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5.2 ) Disadvantages \n",
    "\n",
    "1. Does not work well with large dataset as calculating distances between each data instance would be very costly.\n",
    "<space>\n",
    "\n",
    "2. Does not work well with high dimensionality as this will complicate the distance calculating process to calculate distance for each dimension.\n",
    "<space>\n",
    "\n",
    "3. Sensitive to noisy and missing data\n",
    "<space>\n",
    "\n",
    "4. Feature Scaling- Data in all the dimension should be scaled (normalized and standardized) properly .\n",
    "\n",
    "You can see this part in the JupyterNotebook file called **knn.jpynb** "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7344605b21bb892"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T16:11:15.436885Z",
     "start_time": "2024-01-27T16:11:15.435164Z"
    }
   },
   "id": "841e6c57610be46e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
